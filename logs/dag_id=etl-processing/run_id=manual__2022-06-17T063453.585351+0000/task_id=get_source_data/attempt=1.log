[2022-06-17 06:34:54,837] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl-processing.get_source_data manual__2022-06-17T06:34:53.585351+00:00 [queued]>
[2022-06-17 06:34:54,863] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: etl-processing.get_source_data manual__2022-06-17T06:34:53.585351+00:00 [queued]>
[2022-06-17 06:34:54,864] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2022-06-17 06:34:54,865] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2022-06-17 06:34:54,865] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2022-06-17 06:34:54,927] {taskinstance.py:1377} INFO - Executing <Task(_PythonDecoratedOperator): get_source_data> on 2022-06-17 06:34:53.585351+00:00
[2022-06-17 06:34:54,945] {standard_task_runner.py:52} INFO - Started process 2295 to run task
[2022-06-17 06:34:54,954] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl-processing', 'get_source_data', 'manual__2022-06-17T06:34:53.585351+00:00', '--job-id', '489', '--raw', '--subdir', 'DAGS_FOLDER/testing_etl.py', '--cfg-path', '/tmp/tmp0wx1_0_g', '--error-file', '/tmp/tmpz1mm_3op']
[2022-06-17 06:34:54,956] {standard_task_runner.py:80} INFO - Job 489: Subtask get_source_data
[2022-06-17 06:34:55,148] {task_command.py:370} INFO - Running <TaskInstance: etl-processing.get_source_data manual__2022-06-17T06:34:53.585351+00:00 [running]> on host fe209149cfc1
[2022-06-17 06:34:55,760] {taskinstance.py:1571} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=etl-processing
AIRFLOW_CTX_TASK_ID=get_source_data
AIRFLOW_CTX_EXECUTION_DATE=2022-06-17T06:34:53.585351+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-06-17T06:34:53.585351+00:00
[2022-06-17 06:34:56,666] {base.py:68} INFO - Using connection ID 'mysql_con' for task execution.
[2022-06-17 06:34:56,715] {python.py:173} INFO - Done. Returned value was: {'ID': {0: 4567890, 1: 4567891, 2: 4567892, 3: 4567893, 4: 4567894, 5: 4567895, 6: 4567896, 7: 4567897, 8: 4567898, 9: 4567899, 10: 4567901, 11: 4567902, 12: 4567903, 13: 4567904, 14: 4567905, 15: 4567906, 16: 4567907, 17: 4567908, 18: 4567988}, 'NAME': {0: 'Müşteri1', 1: 'Müşteri1', 2: 'Müşteri1', 3: 'Müşteri1', 4: 'Müşteri3', 5: 'Müşteri3', 6: 'Müşteri4', 7: 'Müşteri4', 8: 'Müşteri4', 9: 'Müşteri4', 10: 'Müşteri6', 11: 'Müşteri7', 12: 'Müşteri7', 13: 'Müşteri8', 14: 'Müşteri9', 15: 'Müşteri6', 16: 'Müşteri11', 17: 'Müşteri12', 18: 'Müşteri10'}, 'CITY': {0: 'İstanbul', 1: 'İstanbul', 2: 'İstanbul', 3: 'İstanbul', 4: 'Ankara', 5: 'Ankara', 6: 'Kastamonu', 7: 'Kastamonu', 8: 'Kastamonu', 9: 'Kastamonu', 10: 'Kastamonu', 11: 'Batman', 12: 'Kastamonu', 13: 'Ankara', 14: 'Ankara', 15: 'Kastamonu', 16: 'Kocaeli', 17: 'Sakarya', 18: 'Ankara'}, 'CREATE_DATE': {0: Timestamp('2021-02-01 00:00:00'), 1: Timestamp('2021-02-01 00:00:00'), 2: Timestamp('2021-02-01 00:00:00'), 3: Timestamp('2021-02-01 00:00:00'), 4: Timestamp('2021-03-01 00:00:00'), 5: Timestamp('2021-03-01 00:00:00'), 6: Timestamp('2021-04-01 00:00:00'), 7: Timestamp('2021-04-01 00:00:00'), 8: Timestamp('2021-04-01 00:00:00'), 9: Timestamp('2021-04-01 00:00:00'), 10: Timestamp('2021-05-01 00:00:00'), 11: Timestamp('2021-06-01 00:00:00'), 12: Timestamp('2021-07-01 00:00:00'), 13: Timestamp('2021-08-01 00:00:00'), 14: Timestamp('2021-09-01 00:00:00'), 15: Timestamp('2021-05-01 00:00:00'), 16: Timestamp('2021-09-01 00:00:00'), 17: Timestamp('2021-08-01 00:00:00'), 18: Timestamp('2021-09-01 00:00:00')}}
[2022-06-17 06:34:56,732] {xcom.py:585} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2022-06-17 06:34:56,734] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2392, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 68, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 197, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 582, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type Timestamp is not JSON serializable
[2022-06-17 06:34:56,806] {taskinstance.py:1400} INFO - Marking task as FAILED. dag_id=etl-processing, task_id=get_source_data, execution_date=20220617T063453, start_date=20220617T063454, end_date=20220617T063456
[2022-06-17 06:34:56,886] {standard_task_runner.py:97} ERROR - Failed to execute job 489 for task get_source_data (Object of type Timestamp is not JSON serializable; 2295)
[2022-06-17 06:34:56,933] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-06-17 06:34:56,998] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
